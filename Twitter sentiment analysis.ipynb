{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The objective of this task is to detect hate speech in tweets. For the sake of simplicity, we say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.\n",
    "\n",
    "Formally, given a training sample of tweets and labels, where label '1' denotes the tweet is racist/sexist and label '0' denotes the tweet is not racist/sexist, your objective is to predict the labels on the test dataset.\n",
    "\n",
    " \n",
    "\n",
    "## Motivation\n",
    "\n",
    "Hate  speech  is  an  unfortunately  common  occurrence  on  the  Internet.  Often social media sites like Facebook and Twitter face the problem of identifying and censoring  problematic  posts  while weighing the right to freedom of speech. The  importance  of  detecting  and  moderating hate  speech  is  evident  from  the  strong  connection between hate speech and actual hate crimes. Early identification of users promoting  hate  speech  could  enable  outreach  programs that attempt to prevent an escalation from speech to action. Sites such as Twitter and Facebook have been seeking  to  actively  combat  hate  speech. In spite of these reasons, NLP research on hate speech has been very limited, primarily due to the lack of a general definition of hate speech, an analysis of its demographic influences, and an investigation of the most effective features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run  \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2                                                                                                         bihday your majesty  \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦    \n",
       "4                                                                                      factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see complete width of tweet column\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "#Reading the dataset\n",
    "\n",
    "df=pd.read_csv('twitter_train.csv')\n",
    "df_test=pd.read_csv('twitter_test.csv')\n",
    "\n",
    "# To see first 5 rows of dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððððððâ¤ï¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisolm. #shame #imwithher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw to work is sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary, #wso condemns  act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "31957  31958      0   \n",
       "31958  31959      0   \n",
       "31959  31960      0   \n",
       "31960  31961      1   \n",
       "31961  31962      0   \n",
       "\n",
       "                                                                                                                                     tweet  \n",
       "31957                                                                 ate @user isz that youuu?ðððððððððâ¤ï¸   \n",
       "31958    to see nina turner on the airwaves trying to wrap herself in the mantle of a genuine hero like shirley chisolm. #shame #imwithher  \n",
       "31959                                                                      listening to sad songs on a monday morning otw to work is sad    \n",
       "31960                                                                  @user #sikh #temple vandalised in in #calgary, #wso condemns  act    \n",
       "31961                                                                                                     thank you @user for you follow    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check last 5 rows of dataset\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run  \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked  \n",
       "2                                                                                                         bihday your majesty  \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦    \n",
       "4                                                                                      factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s check out a few non racist/sexist tweets.\n",
    "\n",
    "df[df['label']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'build the wall' chant '' #tcot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #seashepherd #helpcovedolphins #thecove  #helpcovedolphins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>it's unbelievable that in the 21st century we'd need something like this. again. #neverump  #xenophobia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label  \\\n",
       "13  14      1   \n",
       "14  15      1   \n",
       "17  18      1   \n",
       "23  24      1   \n",
       "34  35      1   \n",
       "\n",
       "                                                                                                       tweet  \n",
       "13                                @user #cnn calls #michigan middle school 'build the wall' chant '' #tcot    \n",
       "14     no comment!  in #australia   #opkillingbay #seashepherd #helpcovedolphins #thecove  #helpcovedolphins  \n",
       "17                                                                                    retweet if you agree!   \n",
       "23                                                           @user @user lumpy says i am a . prove it lumpy.  \n",
       "34  it's unbelievable that in the 21st century we'd need something like this. again. #neverump  #xenophobia   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s check out a few racist/sexist tweets.\n",
    "\n",
    "df[df['label']==1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a many words and characters which are not really required. So, we will try to keep only those words which are important and add value.\n",
    "\n",
    "Let’s check dimensions of the train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the train dataset, we have 2,242 (7%) tweets labeled as racist or sexist, and 29,720 (93%) tweets labeled as non racist/sexist. So, it is an imbalanced classification challenge.\n",
    "\n",
    "Now we will check the distribution of length of the tweets, in terms of words, in both train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_len = df['tweet'].str.len()\n",
    "test_tweet_len=df_test['tweet'].str.len()\n",
    "plt.hist(tweet_len,bins=20,label='train')\n",
    "plt.hist(test_tweet_len,bins=20,label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any natural language processing task, cleaning raw text data is an important step. It helps in getting rid of the unwanted words and characters which helps in obtaining better features. If we skip this step then there is a higher chance that you are working with noisy and inconsistent data. The objective of this step is to clean noise those are less relevant to find the sentiment of tweets such as punctuation, special characters, numbers, and terms which don’t carry much weightage in context to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['nice_tweet']=df['tweet'].str.replace('@[a-zA-Z]*','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Removing Twitter Handles (@user)\n",
    "\n",
    "Let’s create a new column tidy_tweet, it will contain the cleaned and processed tweets. Note that we have passed “@[]*” as the pattern to the remove_pattern function. It is actually a regular expression which will pick any word starting with ‘@’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "df['nice_tweet']=0\n",
    "for i in range(len(df['tweet'])):\n",
    "    #r=re.findall('@[a-zA-Z]*', df['tweet'][i])\n",
    "    #for j in r:\n",
    "    df['nice_tweet'][i]=re.sub('@[a-zA-Z]*','',df['tweet'][i])\n",
    "    \n",
    "df_test['nice_tweet']=0\n",
    "for i in range(len(df_test['tweet'])):\n",
    "    #r=re.findall('@[a-zA-Z]*', df['tweet'][i])\n",
    "    #for j in r:\n",
    "    df_test['nice_tweet'][i]=re.sub('@[a-zA-Z]*','',df_test['tweet'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing Punctuations, Numbers, and Special Characters\n",
    "\n",
    "Here we will replace everything except characters and hashtags with spaces. The regular expression “[^a-zA-Z#]” means anything except alphabets and ‘#’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df['nice_tweet'])):\n",
    "    df['nice_tweet'][i]=re.sub('[^a-zA-Z#\\s]*','',df['nice_tweet'][i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(len(df_test['nice_tweet'])):\n",
    "    df_test['nice_tweet'][i]=re.sub('[^a-zA-Z#\\s]*','',df_test['nice_tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nice_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>when a father is dysfunctional and is so selfish he drags his kids into his dysfunction   #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thanks for #lyft credit i cant use cause they dont offer wheelchair vans in pdx    #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>#model   i love u take with u all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "                                                                                                      nice_tweet  \n",
       "0                 when a father is dysfunctional and is so selfish he drags his kids into his dysfunction   #run  \n",
       "1    thanks for #lyft credit i cant use cause they dont offer wheelchair vans in pdx    #disapointed #getthanked  \n",
       "2                                                                                            bihday your majesty  \n",
       "3                                                           #model   i love u take with u all the time in ur \n",
       "    \n",
       "4                                                                          factsguide society now    #motivation  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Removing Short Words\n",
    "\n",
    "We have to be a little careful here in selecting the length of the words which we want to remove. So, I have decided to remove all the words having length 3 or less. For example, terms like “hmm”, “oh” are of very little use. It is better to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nice_tweet'] = df['nice_tweet'].apply(lambda x : ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['nice_tweet'] = df_test['nice_tweet'].apply(lambda x : ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nice_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>when father dysfunctional selfish drags kids into dysfunction #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thanks #lyft credit cant cause they dont offer wheelchair vans #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "                                                                                nice_tweet  \n",
       "0                       when father dysfunctional selfish drags kids into dysfunction #run  \n",
       "1  thanks #lyft credit cant cause they dont offer wheelchair vans #disapointed #getthanked  \n",
       "2                                                                      bihday your majesty  \n",
       "3                                                               #model love take with time  \n",
       "4                                                           factsguide society #motivation  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text Normalization\n",
    "\n",
    "Here we will use nltk’s PorterStemmer() function to normalize the tweets. But before that we will have to tokenize the tweets. Tokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(df['nice_tweet'])):    \n",
    "#    df['nice_tweet'][i] = nltk.word_tokenize(df['nice_tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "#for i in range(len(df['nice_tweet'])):\n",
    "#    df['nice_tweet'][i] = [lemmatizer.lemmatize(word) for word in df['nice_tweet'][i]]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above given code takes too much time to run and as an data analyst we cant be happy with this lines of code since we are going to work with very huge dataset aso i have wriiten alternative code for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nice_tweet'] = df['nice_tweet'].apply(lambda x : x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nice_tweet'] = df['nice_tweet'].apply(lambda y :  [lemmatizer.lemmatize(w) for w in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['nice_tweet'] = df_test['nice_tweet'].apply(lambda x : x.split())\n",
    "df_test['nice_tweet'] = df_test['nice_tweet'].apply(lambda y :  [lemmatizer.lemmatize(w) for w in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nice_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>[when, father, dysfunctional, selfish, drag, kid, into, dysfunction, #run]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>[thanks, #lyft, credit, cant, cause, they, dont, offer, wheelchair, van, #disapointed, #getthanked]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>[#model, love, take, with, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>[factsguide, society, #motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "                                                                                            nice_tweet  \n",
       "0                           [when, father, dysfunctional, selfish, drag, kid, into, dysfunction, #run]  \n",
       "1  [thanks, #lyft, credit, cant, cause, they, dont, offer, wheelchair, van, #disapointed, #getthanked]  \n",
       "2                                                                              [bihday, your, majesty]  \n",
       "3                                                                     [#model, love, take, with, time]  \n",
       "4                                                                   [factsguide, society, #motivation]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets sttitch this token back to retreive our cleaned tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df['nice_tweet'])):    \n",
    "    df['nice_tweet'][i] = ' '.join(df['nice_tweet'][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_test['nice_tweet'])):    \n",
    "    df_test['nice_tweet'][i] = ' '.join(df_test['nice_tweet'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nice_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run</td>\n",
       "      <td>when father dysfunctional selfish drag kid into dysfunction #run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked</td>\n",
       "      <td>thanks #lyft credit cant cause they dont offer wheelchair van #disapointed #getthanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in urð±!!! ðððð",
       "ð¦ð¦ð¦</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  \\\n",
       "0   1      0   \n",
       "1   2      0   \n",
       "2   3      0   \n",
       "3   4      0   \n",
       "4   5      0   \n",
       "\n",
       "                                                                                                                        tweet  \\\n",
       "0                       @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run   \n",
       "1  @user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked   \n",
       "2                                                                                                         bihday your majesty   \n",
       "3                                      #model   i love u take with u all the time in urð±!!! ðððð\n",
       "ð¦ð¦ð¦     \n",
       "4                                                                                      factsguide: society now    #motivation   \n",
       "\n",
       "                                                                               nice_tweet  \n",
       "0                        when father dysfunctional selfish drag kid into dysfunction #run  \n",
       "1  thanks #lyft credit cant cause they dont offer wheelchair van #disapointed #getthanked  \n",
       "2                                                                     bihday your majesty  \n",
       "3                                                              #model love take with time  \n",
       "4                                                          factsguide society #motivation  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no', 'now', \"you'll\", 'was', 'because', 'ourselves', \"you'd\", 'under', 'y', \"hadn't\", 'off', 've', 'you', 'been', 'between', 'how', 'there', \"should've\", 'very', 'more', 'if', 'above', 'mightn', 'further', 'hadn', 'once', \"needn't\", 'themselves', 'aren', 'myself', 'is', 'or', 'such', 'yours', 'ours', 'am', 'just', 'this', 'below', 'their', 'itself', 'did', 'the', 'hers', 'and', 'other', 'too', 'about', 't', 'again', \"don't\", 'll', 'couldn', 'mustn', \"wouldn't\", 'with', 'didn', 'for', 'her', 'ain', 'can', 'out', 'ma', 'they', 'up', 'herself', 'that', 'but', 'until', 'both', 'from', 'yourself', 'your', 'hasn', 'having', 'do', 'should', \"shan't\", 'during', 'wouldn', 'we', \"hasn't\", 'while', 'd', 'at', 'of', \"you're\", 'which', 'own', \"wasn't\", 'by', \"doesn't\", 'so', 'it', 'him', 'his', 'through', 'some', 'm', 'be', 'over', 'wasn', 'what', 'in', 'theirs', 'she', \"shouldn't\", 'o', 'isn', \"isn't\", \"didn't\", 'needn', 'into', \"mustn't\", 'why', \"couldn't\", 'he', 'are', 'all', 'has', \"weren't\", 'yourselves', 'will', \"it's\", 'a', 'here', 'haven', 'had', 'then', 'who', 'me', 'few', 'won', 'shan', 'its', 'them', 'same', 'an', 'himself', 'whom', 'our', 'each', \"aren't\", 'have', \"she's\", \"haven't\", 'when', 'those', 'doesn', 'most', 'nor', 'to', 'as', 'after', 'on', \"mightn't\", 'i', 'were', \"won't\", \"you've\", 'against', 'before', 'weren', \"that'll\", 'any', 'don', 'than', 'where', 'being', 'not', 'these', 'only', 'my', 's', 'shouldn', 're', 'does', 'doing', 'down'}\n"
     ]
    }
   ],
   "source": [
    "print(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nice_tweet'] = df['nice_tweet'].apply(lambda x : ' '.join([w for w in x.split() if not w in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['nice_tweet'] = df_test['nice_tweet'].apply(lambda x : ' '.join([w for w in x.split() if not w in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(max_df = 0.9 , min_df = 2 , stop_words = 'english' , max_features = 1000)\n",
    "dff = count_vectorizer.fit_transform(df['nice_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.9 , min_df = 2 , stop_words = 'english' , max_features = 1000)\n",
    "dfff = tfidf_vectorizer.fit_transform(df['nice_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 1000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dff[:20000 , :]\n",
    "test_x = dff[20000: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df['label'][:20000]\n",
    "test_y = df['label'][20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(train_x , train_y)\n",
    "pred = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11039,   582],\n",
       "       [   66,   275]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.confusion_matrix(pred , test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9458284567798028"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(pred , test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97     11621\n",
      "           1       0.32      0.81      0.46       341\n",
      "\n",
      "    accuracy                           0.95     11962\n",
      "   macro avg       0.66      0.88      0.72     11962\n",
      "weighted avg       0.97      0.95      0.96     11962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred , test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10549   363]\n",
      " [  556   494]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User-1\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:71: FutureWarning: Pass threshold=0.15 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "y_prob=lr.predict_proba(test_x)[:,1]\n",
    "pred1=binarize([y_prob],0.15)[0]\n",
    "print(metrics.confusion_matrix(pred1,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     10912\n",
      "         1.0       0.58      0.47      0.52      1050\n",
      "\n",
      "    accuracy                           0.92     11962\n",
      "   macro avg       0.76      0.72      0.74     11962\n",
      "weighted avg       0.92      0.92      0.92     11962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(pred1 , test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METHOD - 2 Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "\n",
    "onehot_repr=[one_hot(words,5000)for words in df['nice_tweet']] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "embedded_doc = pad_sequences(onehot_repr , padding = 'pre' , maxlen = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 50)            250000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 310,501\n",
      "Trainable params: 310,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , LSTM , Bidirectional , Embedding\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(5000 , 50 ,input_length=20))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999/999 [==============================] - 27s 23ms/step - loss: 0.2344 - accuracy: 0.9343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23b02e2cec8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_lstm = np.array(embedded_doc)\n",
    "y_lstm = df['label']\n",
    "model.fit(X_lstm , y_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict_classes(X_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while using lstm training accuracy is around 95 % whereas while using concepts of nlp like vectorizer accuracy is just 50 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
